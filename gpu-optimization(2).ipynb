{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31154,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"%pip install -q gradio gradio_imageslider scikit-image\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-04T10:04:41.752798Z","iopub.execute_input":"2025-11-04T10:04:41.753010Z","iopub.status.idle":"2025-11-04T10:04:45.175906Z","shell.execute_reply.started":"2025-11-04T10:04:41.752992Z","shell.execute_reply":"2025-11-04T10:04:45.175034Z"}},"outputs":[{"name":"stdout","text":"Note: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"#Imports\nimport os, time, math, statistics\nimport numpy as np\nfrom PIL import Image\nimport pandas as pd\n\nimport torch\nimport torch.nn.functional as F\nimport triton\nimport triton.language as tl\n\nfrom skimage.metrics import peak_signal_noise_ratio as sk_psnr, structural_similarity as sk_ssim\nfrom skimage import exposure\n\nprint(\"CUDA available:\", torch.cuda.is_available())\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\nprint(\"Device:\", device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-04T10:04:57.047038Z","iopub.execute_input":"2025-11-04T10:04:57.047382Z","iopub.status.idle":"2025-11-04T10:05:02.564349Z","shell.execute_reply.started":"2025-11-04T10:04:57.047353Z","shell.execute_reply":"2025-11-04T10:05:02.563669Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# =======================\n# Triton Kernels (manual tuning only; no @triton.autotune to avoid conflicts)\n# =======================\n@triton.jit\ndef conv2d_tiled_kernel(\n    img_ptr, out_ptr, ker_ptr,\n    H, W, K,\n    STRIDE_H, STRIDE_W, OUT_STRIDE_H, OUT_STRIDE_W,\n    TILE_H: tl.constexpr, TILE_W: tl.constexpr\n):\n    pid_h = tl.program_id(0)\n    pid_w = tl.program_id(1)\n    r = (K - 1) // 2\n    oh0 = pid_h * TILE_H\n    ow0 = pid_w * TILE_W\n    oh = oh0 + tl.arange(0, TILE_H)\n    ow = ow0 + tl.arange(0, TILE_W)\n    acc = tl.zeros((TILE_H, TILE_W), dtype=tl.float32)\n    for ky in range(0, K):\n        for kx in range(0, K):\n            ih = oh[:, None] + (ky - r)\n            iw = ow[None, :] + (kx - r)\n            mask = (ih >= 0) & (ih < H) & (iw >= 0) & (iw < W)\n            pix = tl.load(img_ptr + ih * STRIDE_H + iw * STRIDE_W, mask=mask, other=0.0)\n            cof = tl.load(ker_ptr + ky * K + kx)\n            acc += pix * cof\n    out_block = tl.make_block_ptr(\n        base=out_ptr, shape=(H, W), strides=(OUT_STRIDE_H, OUT_STRIDE_W),\n        offsets=(oh0, ow0), block_shape=(TILE_H, TILE_W), order=(1, 0),\n    )\n    tl.store(out_block, acc, boundary_check=(0, 1))\n\n@triton.jit\ndef conv1d_row_kernel(\n    img_ptr, tmp_ptr, ker_row_ptr,\n    H, W, K,\n    SIH, SIW, SOH, SOW,\n    TILE_H: tl.constexpr, TILE_W: tl.constexpr\n):\n    pid_h = tl.program_id(0)\n    pid_w = tl.program_id(1)\n    r = (K - 1)//2\n    oh0 = pid_h * TILE_H\n    ow0 = pid_w * TILE_W\n    oh = oh0 + tl.arange(0, TILE_H)\n    ow = ow0 + tl.arange(0, TILE_W)\n    acc = tl.zeros((TILE_H, TILE_W), dtype=tl.float32)\n    for kx in range(0, K):\n        ih = oh[:, None]\n        iw = ow[None, :] + (kx - r)\n        mask = (ih >= 0) & (ih < H) & (iw >= 0) & (iw < W)\n        pix = tl.load(img_ptr + ih * SIH + iw * SIW, mask=mask, other=0.0)\n        cof = tl.load(ker_row_ptr + kx)\n        acc += pix * cof\n    tmp_block = tl.make_block_ptr(\n        base=tmp_ptr, shape=(H, W), strides=(SOH, SOW),\n        offsets=(oh0, ow0), block_shape=(TILE_H, TILE_W), order=(1, 0),\n    )\n    tl.store(tmp_block, acc, boundary_check=(0, 1))\n\n@triton.jit\ndef conv1d_col_kernel(\n    tmp_ptr, out_ptr, ker_col_ptr,\n    H, W, K,\n    SIH, SIW, SOH, SOW,\n    TILE_H: tl.constexpr, TILE_W: tl.constexpr\n):\n    pid_h = tl.program_id(0)\n    pid_w = tl.program_id(1)\n    r = (K - 1)//2\n    oh0 = pid_h * TILE_H\n    ow0 = pid_w * TILE_W\n    oh = oh0 + tl.arange(0, TILE_H)\n    ow = ow0 + tl.arange(0, TILE_W)\n    acc = tl.zeros((TILE_H, TILE_W), dtype=tl.float32)\n    for ky in range(0, K):\n        ih = oh[:, None] + (ky - r)\n        iw = ow[None, :]\n        mask = (ih >= 0) & (ih < H) & (iw >= 0) & (iw < W)\n        pix = tl.load(tmp_ptr + ih * SIH + iw * SIW, mask=mask, other=0.0)\n        cof = tl.load(ker_col_ptr + ky)\n        acc += pix * cof\n    out_block = tl.make_block_ptr(\n        base=out_ptr, shape=(H, W), strides=(SOH, SOW),\n        offsets=(oh0, ow0), block_shape=(TILE_H, TILE_W), order=(1, 0),\n    )\n    tl.store(out_block, acc, boundary_check=(0, 1))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-04T10:04:57.047038Z","iopub.execute_input":"2025-11-04T10:04:57.047382Z","iopub.status.idle":"2025-11-04T10:05:02.564349Z","shell.execute_reply.started":"2025-11-04T10:04:57.047353Z","shell.execute_reply":"2025-11-04T10:05:02.563669Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# =======================\n# Reference & Timing Utils\n# =======================\ndef conv2d_ref(img_2d, ker_2d):\n    img = img_2d[None,None]\n    ker = ker_2d[None,None]\n    pad = ker.shape[-1]//2\n    return F.conv2d(img, ker, padding=pad).squeeze(0).squeeze(0)\n\nCANDIDATE_TILES = [(16,16), (32,16), (16,32), (32,32), (64,32), (32,64), (64,64)]\nCANDIDATE_WARPS = [4, 8]\n\ndef time_kernel(call, reps=10, warmup=2):\n    for _ in range(warmup):\n        call()\n        torch.cuda.synchronize()\n    times = []\n    for _ in range(reps):\n        torch.cuda.synchronize()\n        t0 = time.time()\n        call()\n        torch.cuda.synchronize()\n        times.append(time.time() - t0)\n    med = statistics.median(times)\n    p20 = statistics.quantiles(times, n=5)[0]\n    p80 = statistics.quantiles(times, n=5)[-1]\n    return med, (p20, p80)\n\n# Prealloc scratch buffers for stable timing\n_scratch_out2d = torch.empty((4096, 4096), device=device, dtype=torch.float32)\n_scratch_tmp   = torch.empty((4096, 4096), device=device, dtype=torch.float32)\n_scratch_u = torch.ones(65, device=device, dtype=torch.float32) / 65\n_scratch_v = torch.ones(65, device=device, dtype=torch.float32) / 65","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-04T10:04:57.047038Z","iopub.execute_input":"2025-11-04T10:04:57.047382Z","iopub.status.idle":"2025-11-04T10:05:02.564349Z","shell.execute_reply.started":"2025-11-04T10:04:57.047353Z","shell.execute_reply":"2025-11-04T10:05:02.563669Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# =======================\n# Manual Tuning (sweep TILE/warps)\n# =======================\ndef tune_conv2d(img, ker, H, W, K, tiles=CANDIDATE_TILES, warps=CANDIDATE_WARPS, reps=8, warmup=2):\n    best = None\n    for th, tw in tiles:\n        grid = (triton.cdiv(H, th), triton.cdiv(W, tw))\n        for nw in warps:\n            def launch():\n                conv2d_tiled_kernel[grid](\n                    img, _scratch_out2d, ker,\n                    H, W, K,\n                    img.stride(0), img.stride(1),\n                    _scratch_out2d.stride(0), _scratch_out2d.stride(1),\n                    TILE_H=th, TILE_W=tw, num_warps=nw\n                )\n            med, _ = time_kernel(launch, reps=reps, warmup=warmup)\n            if (best is None) or (med < best[0]):\n                best = (med, th, tw, nw)\n    return {\"latency_s\": best[0], \"TILE_H\": best[1], \"TILE_W\": best[2], \"num_warps\": best[3]}\n\ndef tune_sep_rowcol(img, H, W, K, tiles=CANDIDATE_TILES, warps=CANDIDATE_WARPS, reps=8, warmup=2):\n    best = None\n    tmp = _scratch_tmp\n    u = _scratch_u[:K]; v = _scratch_v[:K]\n    for th, tw in tiles:\n        grid = (triton.cdiv(H, th), triton.cdiv(W, tw))\n        for nw in warps:\n            def launch_pair():\n                conv1d_row_kernel[grid](\n                    img, tmp, v, H, W, v.numel(),\n                    img.stride(0), img.stride(1),\n                    tmp.stride(0), tmp.stride(1),\n                    TILE_H=th, TILE_W=tw, num_warps=nw\n                )\n                conv1d_col_kernel[grid](\n                    tmp, _scratch_out2d, u, H, W, u.numel(),\n                    tmp.stride(0), tmp.stride(1),\n                    _scratch_out2d.stride(0), _scratch_out2d.stride(1),\n                    TILE_H=th, TILE_W=tw, num_warps=nw\n                )\n            med, _ = time_kernel(launch_pair, reps=reps, warmup=warmup)\n            if (best is None) or (med < best[0]):\n                best = (med, th, tw, nw)\n    return {\"latency_s\": best[0], \"TILE_H\": best[1], \"TILE_W\": best[2], \"num_warps\": best[3]}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-04T10:04:57.047038Z","iopub.execute_input":"2025-11-04T10:04:57.047382Z","iopub.status.idle":"2025-11-04T10:05:02.564349Z","shell.execute_reply.started":"2025-11-04T10:04:57.047353Z","shell.execute_reply":"2025-11-04T10:05:02.563669Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# =======================\n# Steady-State Runners\n# =======================\ndef run_conv2d_steady(img, ker, reps=10, warmup=3):\n    H, W = img.shape\n    K = ker.shape[0]\n    out = torch.empty_like(img)\n    best = tune_conv2d(img, ker, H, W, K, reps=max(4,reps//2), warmup=max(2,warmup//2))\n    th, tw, nw = best[\"TILE_H\"], best[\"TILE_W\"], best[\"num_warps\"]\n    grid = (triton.cdiv(H, th), triton.cdiv(W, tw))\n    def launch():\n        conv2d_tiled_kernel[grid](\n            img, out, ker, H, W, K,\n            img.stride(0), img.stride(1),\n            out.stride(0), out.stride(1),\n            TILE_H=th, TILE_W=tw, num_warps=nw\n        )\n    med, (p20,p80) = time_kernel(launch, reps=reps, warmup=warmup)\n    mpix_s = (H*W)/(med*1e6)\n    return out, {\"MPix/s\": mpix_s, \"latency_s\": med, \"p20_s\": p20, \"p80_s\": p80,\n                 \"TILE_H\": th, \"TILE_W\": tw, \"num_warps\": nw}\n\ndef run_separable_steady(img, u, v, reps=10, warmup=3):\n    H, W = img.shape\n    K = v.numel()\n    tmp = torch.empty_like(img)\n    out = torch.empty_like(img)\n    best = tune_sep_rowcol(img, H, W, K, reps=max(4,reps//2), warmup=max(2,warmup//2))\n    th, tw, nw = best[\"TILE_H\"], best[\"TILE_W\"], best[\"num_warps\"]\n    grid = (triton.cdiv(H, th), triton.cdiv(W, tw))\n    def launch_pair():\n        conv1d_row_kernel[grid](\n            img, tmp, v, H, W, v.numel(),\n            img.stride(0), img.stride(1),\n            tmp.stride(0), tmp.stride(1),\n            TILE_H=th, TILE_W=tw, num_warps=nw\n        )\n        conv1d_col_kernel[grid](\n            tmp, out, u, H, W, u.numel(),\n            tmp.stride(0), tmp.stride(1),\n            out.stride(0), out.stride(1),\n            TILE_H=th, TILE_W=tw, num_warps=nw\n        )\n    med, (p20,p80) = time_kernel(launch_pair, reps=reps, warmup=warmup)\n    mpix_s = (H*W)/(med*1e6)\n    return out, {\"MPix/s\": mpix_s, \"latency_s\": med, \"p20_s\": p20, \"p80_s\": p80,\n                 \"TILE_H\": th, \"TILE_W\": tw, \"num_warps\": nw}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-04T10:04:57.047038Z","iopub.execute_input":"2025-11-04T10:04:57.047382Z","iopub.status.idle":"2025-11-04T10:05:02.564349Z","shell.execute_reply.started":"2025-11-04T10:04:57.047353Z","shell.execute_reply":"2025-11-04T10:05:02.563669Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# =======================\n# Filters & Evaluation\n# =======================\nFILTERS = {\n    \"gaussian3x3\": np.array([[1,2,1],[2,4,2],[1,2,1]], dtype=np.float32)/16.0,\n    \"gaussian5x5\": np.array([[1,4,6,4,1],[4,16,24,16,4],[6,24,36,24,6],[4,16,24,16,4],[1,4,6,4,1]], dtype=np.float32)/256.0,\n    \"box3x3\": np.ones((3,3), dtype=np.float32)/9.0,\n    \"sobel_h\": np.array([[-1,0,1],[-2,0,2],[-1,0,1]], dtype=np.float32)/8.0,\n    \"sobel_v\": np.array([[-1,-2,-1],[0,0,0],[1,2,1]], dtype=np.float32)/8.0,\n    \"laplacian\": np.array([[0,-1,0],[-1,4,-1],[0,-1,0]], dtype=np.float32),\n}\n\ndef compute_gflops(H, W, K, latency_s):\n    flops = H * W * 2 * K * K\n    return flops / (latency_s * 1e9)\n\ndef evaluate_once(img_np, filter_name=\"gaussian5x5\", algo=\"2D\", reps=10, warmup=3):\n    ker_np = FILTERS[filter_name]\n    K = ker_np.shape[0]\n    img = torch.from_numpy(img_np).to(device, dtype=torch.float32)\n    ker = torch.from_numpy(ker_np).to(device, dtype=torch.float32)\n    ref = conv2d_ref(img.cpu(), ker.cpu()).to(device)\n    if algo.lower().startswith(\"sep\"):\n        u = torch.ones(K, device=device, dtype=torch.float32)/K\n        v = torch.ones(K, device=device, dtype=torch.float32)/K\n        out, perf = run_separable_steady(img, u, v, reps=reps, warmup=warmup)\n    else:\n        out, perf = run_conv2d_steady(img, ker, reps=reps, warmup=warmup)\n    out_np = out.detach().cpu().numpy().clip(0,1)\n    ref_np = ref.detach().cpu().numpy().clip(0,1)\n    psnr = sk_psnr(ref_np, out_np, data_range=1.0)\n    ssim = sk_ssim(ref_np, out_np, data_range=1.0)\n    max_err = float(np.max(np.abs(out_np - ref_np)))\n    gflops = compute_gflops(img_np.shape[0], img_np.shape[1], K, perf[\"latency_s\"])\n    return out_np, {\n        \"MPix/s\": perf[\"MPix/s\"], \"latency_s\": perf[\"latency_s\"], \"GFLOPS\": gflops,\n        \"TILE_H\": perf[\"TILE_H\"], \"TILE_W\": perf[\"TILE_W\"], \"num_warps\": perf[\"num_warps\"],\n        \"PSNR_dB_vs_ref\": psnr, \"SSIM_vs_ref\": ssim, \"max_abs_err_vs_ref\": max_err\n    }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-04T10:04:57.047038Z","iopub.execute_input":"2025-11-04T10:04:57.047382Z","iopub.status.idle":"2025-11-04T10:05:02.564349Z","shell.execute_reply.started":"2025-11-04T10:04:57.047353Z","shell.execute_reply":"2025-11-04T10:05:02.563669Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# =======================\n# New: Gaussian Denoise / Unsharp / CLAHE\n# =======================\ndef gaussian_kernel(size, sigma):\n    ax = torch.arange(size, device=device, dtype=torch.float32) - (size - 1)/2\n    xx, yy = torch.meshgrid(ax, ax, indexing='ij')\n    ker = torch.exp(-(xx*xx + yy*yy) / (2.0 * sigma * sigma))\n    ker = ker / ker.sum()\n    return ker\n\ndef evaluate_with_kernel(img_np, ker_np, algo=\"2D\", reps=10, warmup=3):\n    img = torch.from_numpy(img_np).to(device, dtype=torch.float32)\n    ker = torch.from_numpy(ker_np.astype(np.float32)).to(device, dtype=torch.float32)\n    ref = conv2d_ref(img.cpu(), ker.cpu()).to(device)\n    if algo.lower().startswith(\"sep\"):\n        K = ker.shape[0]\n        u = torch.ones(K, device=device, dtype=torch.float32)/K\n        v = torch.ones(K, device=device, dtype=torch.float32)/K\n        out, perf = run_separable_steady(img, u, v, reps=reps, warmup=warmup)\n    else:\n        out, perf = run_conv2d_steady(img, ker, reps=reps, warmup=warmup)\n    out_np = out.detach().cpu().numpy().clip(0,1)\n    ref_np = ref.detach().cpu().numpy().clip(0,1)\n    psnr = sk_psnr(ref_np, out_np, data_range=1.0)\n    ssim = sk_ssim(ref_np, out_np, data_range=1.0)\n    max_err = float(np.max(np.abs(out_np - ref_np)))\n    gflops = compute_gflops(img_np.shape[0], img_np.shape[1], ker_np.shape[0], perf[\"latency_s\"])\n    return out_np, {\n        \"MPix/s\": perf[\"MPix/s\"], \"latency_s\": perf[\"latency_s\"], \"GFLOPS\": gflops,\n        \"TILE_H\": perf[\"TILE_H\"], \"TILE_W\": perf[\"TILE_W\"], \"num_warps\": perf[\"num_warps\"],\n        \"PSNR_dB_vs_ref\": psnr, \"SSIM_vs_ref\": ssim, \"max_abs_err_vs_ref\": max_err\n    }\n\ndef unsharp_mask_gpu(img_np, K=5, sigma=1.0, amount=1.0, algo=\"2D\", reps=10, warmup=3):\n    ker = gaussian_kernel(K, sigma)\n    img = torch.from_numpy(img_np).to(device, dtype=torch.float32)\n    if algo.lower().startswith(\"sep\"):\n        u = torch.ones(K, device=device, dtype=torch.float32)/K\n        v = torch.ones(K, device=device, dtype=torch.float32)/K\n        blurred, perf_blur = run_separable_steady(img, u, v, reps=reps, warmup=warmup)\n    else:\n        blurred, perf_blur = run_conv2d_steady(img, ker, reps=reps, warmup=warmup)\n    enhanced = (img + amount * (img - blurred)).clamp(0,1)\n    out_np = enhanced.detach().cpu().numpy()\n    psnr_orig = sk_psnr(img_np, out_np, data_range=1.0)\n    ssim_orig = sk_ssim(img_np, out_np, data_range=1.0)\n    return out_np, {\n        \"MPix/s\": (img.numel())/(perf_blur[\"latency_s\"]*1e6),\n        \"latency_s\": perf_blur[\"latency_s\"],\n        \"TILE_H\": perf_blur[\"TILE_H\"], \"TILE_W\": perf_blur[\"TILE_W\"], \"num_warps\": perf_blur[\"num_warps\"],\n        \"PSNR_dB_vs_input\": psnr_orig, \"SSIM_vs_input\": ssim_orig\n    }\n\ndef apply_clahe(img_np, clip_limit=0.01):\n    clahe = exposure.equalize_adapthist(img_np, clip_limit=clip_limit)\n    return clahe.astype(np.float32)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-04T10:04:57.047038Z","iopub.execute_input":"2025-11-04T10:04:57.047382Z","iopub.status.idle":"2025-11-04T10:05:02.564349Z","shell.execute_reply.started":"2025-11-04T10:04:57.047353Z","shell.execute_reply":"2025-11-04T10:05:02.563669Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# =======================\n# Gradio Frontend (Before/After + Metrics)\n# =======================\nimport gradio as gr\nfrom gradio_imageslider import ImageSlider  # in-image slider\n\ndef run_pipeline(pil_img, mode, K, sigma, amount, clip_limit, algo, noise_sig, fixed_filter):\n    # Reuse your apply_and_compare internals but also return both images separately\n    # Compute outputs\n    if pil_img is None:\n        N = 1024\n        img_np = (np.indices((N,N)).sum(axis=0) % 2).astype(np.float32)\n    else:\n        arr = np.array(pil_img).astype(np.float32)\n        if arr.ndim == 3:\n            arr = 0.2989*arr[...,0] + 0.5870*arr[...,1] + 0.1140*arr[...,2]\n        img_np = (arr/255.0).clip(0,1)\n    clean_np = img_np.copy()\n    if noise_sig > 0:\n        img_np = np.clip(img_np + np.random.normal(0, noise_sig, img_np.shape).astype(np.float32), 0, 1)\n\n    if mode.startswith(\"Denoise\"):\n        ker = gaussian_kernel(int(K), float(sigma)).detach().cpu().numpy()\n        out_np, m = evaluate_with_kernel(img_np, ker, algo=algo, reps=8, warmup=2)\n        psnr_clean = sk_psnr(clean_np, out_np, data_range=1.0)\n        ssim_clean = sk_ssim(clean_np, out_np, data_range=1.0)\n        metrics_text = (\n            f\"Denoise | K={K} σ={sigma:.2f} | MPix/s={m['MPix/s']:.2f} | \"\n            f\"PSNR(clean,out)={psnr_clean:.2f} dB | SSIM(clean,out)={ssim_clean:.4f} | \"\n            f\"TILE={m['TILE_H']}x{m['TILE_W']} Warps={m['num_warps']}\"\n        )\n    elif mode.startswith(\"Sharpen\"):\n        out_np, m = unsharp_mask_gpu(img_np, K=int(K), sigma=float(sigma), amount=float(amount),\n                                     algo=algo, reps=8, warmup=2)\n        metrics_text = (\n            f\"Unsharp | K={K} σ={sigma:.2f} amount={amount:.2f} | \"\n            f\"MPix/s={m['MPix/s']:.2f} | TILE={m['TILE_H']}x{m['TILE_W']} Warps={m['num_warps']}\"\n        )\n    elif mode.startswith(\"Contrast\"):\n        out_np = apply_clahe(img_np, clip_limit=float(clip_limit))\n        metrics_text = f\"CLAHE | clip_limit={clip_limit:.3f} | (CPU post-process for visualization)\"\n    else:\n        ker_np = FILTERS[fixed_filter].astype(np.float32)\n        out_np, m = evaluate_with_kernel(img_np, ker_np, algo=algo, reps=8, warmup=2)\n        metrics_text = (\n            f\"Fixed Filter {fixed_filter} | MPix/s={m['MPix/s']:.2f} | \"\n            f\"TILE={m['TILE_H']}x{m['TILE_W']} Warps={m['num_warps']}\"\n        )\n\n    before_u8 = Image.fromarray((img_np*255).astype(np.uint8))\n    after_u8  = Image.fromarray((out_np*255).astype(np.uint8))\n    diff_img = Image.fromarray((np.abs(out_np - img_np)*255).astype(np.uint8))\n    return before_u8, after_u8, diff_img, metrics_text, (before_u8, after_u8)\n\nwith gr.Blocks(title=\"GPU-Optimized X-ray Filtering\") as demo:\n    gr.Markdown(\"### GPU Optmization\")\n    with gr.Row():\n        input_img = gr.Image(type=\"pil\", label=\"Input image\")\n    with gr.Row():\n        mode = gr.Radio(\n            [\"Denoise (Gaussian)\", \"Sharpen (Unsharp Mask)\", \"Contrast (CLAHE)\", \"Filter (Fixed Kernel)\"],\n            value=\"Denoise (Gaussian)\", label=\"Mode\"\n        )\n        algo = gr.Radio([\"2D\", \"separable\"], value=\"2D\", label=\"GPU algorithm\")\n        fixed_filter = gr.Dropdown(list(FILTERS.keys()), value=\"gaussian5x5\", label=\"Fixed filter\")\n    with gr.Row():\n        K_slider = gr.Slider(3, 15, value=5, step=2, label=\"Kernel size K (odd)\")\n        sigma_slider = gr.Slider(0.5, 3.0, value=1.0, step=0.1, label=\"Sigma (Gaussian/Unsharp)\")\n        amount_slider = gr.Slider(0.0, 2.0, value=1.0, step=0.1, label=\"Amount (Unsharp)\")\n        clip_slider = gr.Slider(0.005, 0.05, value=0.01, step=0.005, label=\"CLAHE clip_limit\")\n        noise_sigma = gr.Slider(0.0, 0.1, value=0.0, step=0.01, label=\"Add Gaussian noise σ (0..0.1)\")\n\n    with gr.Row():\n        with gr.Column():\n            before_out = gr.Image(label=\"Before\")\n        with gr.Column():\n            after_out = gr.Image(label=\"After\")\n    with gr.Row():\n        slider = ImageSlider(label=\"Drag to Compare\", type=\"pil\")\n    with gr.Row():\n        diff_out = gr.Image(label=\"|Δ| Heatmap\")\n        metrics = gr.Textbox(label=\"Metrics\", lines=6)\n\n    run_btn = gr.Button(\"Run\")\n    def on_run(img, mo, K, si, am, cl, al, ns, ff):\n        b, a, d, txt, pair = run_pipeline(img, mo, K, si, am, cl, al, ns, ff)\n        return b, a, pair, d, txt\n\n    run_btn.click(\n        on_run,\n        inputs=[input_img, mode, K_slider, sigma_slider, amount_slider, clip_slider, algo, noise_sigma, fixed_filter],\n        outputs=[before_out, after_out, slider, diff_out, metrics]\n    )\n\ndemo.launch(share=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-04T10:04:57.047038Z","iopub.execute_input":"2025-11-04T10:04:57.047382Z","iopub.status.idle":"2025-11-04T10:05:02.564349Z","shell.execute_reply.started":"2025-11-04T10:04:57.047353Z","shell.execute_reply":"2025-11-04T10:05:02.563669Z"}},"outputs":[{"name":"stdout","text":"Note: you may need to restart the kernel to use updated packages.\nCUDA available: True\nDevice: cuda\n* Running on local URL:  http://127.0.0.1:7860\n* Running on public URL: https://7335aac8c772584d36.gradio.live\n\nThis share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<div><iframe src=\"https://7335aac8c772584d36.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"},"metadata":{}},{"execution_count":4,"output_type":"execute_result","data":{"text/plain":""},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/skimage/metrics/simple_metrics.py:168: RuntimeWarning: divide by zero encountered in scalar divide\n  return 10 * np.log10((data_range**2) / err)\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}